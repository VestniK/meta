@("int8_t", "uint8_t", "int16_t", "uint16_t", "int", "uint", "const char*")
@//
// Generated by: @program; @version;
// Grammar:      @grm_file;
// Skeleton:     @skl_file;
// Output:       @out_file;
#include <cassert>
#include <cstring>
#include <cstdio>
#include <sstream>

#include "@grm_name;parser.h"
@numb_node?;...
// Should be created manually. Should contain Node sublcasses forward declared in
// the @grm_name;parser.h
#include "@grm_name;nodes.h"
@@

namespace @grm_name; {

SyntaxError::SyntaxError(const std::string &srcPath, const char *input, size_t size, StackFrame *stack, size_t stackSz, int stateNum, const Token &token):
    errorToken(token), src(srcPath)
{
    std::stringstream ss;
    ss << "unexpected symbol " << termNames[token.termNum];
    msg = ss.str();

    ss.str(std::string());
    const char *lineStart = token.start;
    while (lineStart != input && *lineStart != '\r' && *lineStart != '\n')
        --lineStart;
    if (lineStart != token.start && (*lineStart == '\r' || *lineStart == '\n'))
        ++lineStart;
    const char *lineEnd = token.end;
    while (lineEnd != input + size && *lineEnd != '\r' && *lineEnd != '\n')
        ++lineEnd;
    ss << std::string(lineStart, lineEnd - lineStart) << std::endl;
    for (const char *pos = lineStart; pos != lineEnd; ++pos) {
        if (pos == token.start)
            ss << '^';
        else if (isspace(*pos))
            ss << *pos;
        else
            ss << ' ';
    }
    markedLine = ss.str();
    errorToken.end = markedLine.data() + (token.end - lineStart);
    errorToken.start = markedLine.data() + (token.start - lineStart);
@optn_exp?;...

    ss.str(std::string());
    for (size_t termPos = 0; termPos < termsCount; ++termPos) {
        if (
            (Parser::Bm[Parser::Br[stateNum] + Parser::Bc[termPos]] & Parser::Bmask[termPos]) ||
            (Parser::Rr[stateNum] < 0 && Parser::Rm[Parser::Rc[termPos] - Parser::Rr[stateNum]] > 0)
        )
            ss << "\t" << termNames[termPos] << std::endl;
    }
    expectedLine = ss.str();
@@
@optn_exp.gt.1;...

    ss.str(std::string());
    for (size_t pos = 0; pos < stackSz; ++pos) {
        if (stack[stackSz - pos - 1].symbol < 0)
            ss << "\t[" << pos << "] " << nontermNames[-stack[stackSz - pos - 1].symbol] << std::endl;
        else
            ss << "\t[" << pos << "] " << termNames[stack[stackSz - pos - 1].symbol] << std::endl;
    }
    stackDump = ss.str();
@@
}

@optn_exp?;...
const size_t SyntaxError::termsCount = @numb_term.d;;

@@
@term_symb.t; SyntaxError::termNames[] = {
    @term_symb.1|"%s"|, |,\n    |;
};
@optn_exp.gt.1;...

@head_symb.t; SyntaxError::nontermNames[] = {
    @head_symb.1|"%s"|, |,\n    |;
};
@@
@numb_node?;...

Node::Node(const StackFrame *start, size_t size)
{
    for (size_t i = 0; i < size; ++i) {
        children.insert(children.end(), start[i].nodes.begin(), start[i].nodes.end());
        srcTokens.join(start[i].tokens);
    }
}

void Node::walk(Visitor *visitor, int depth)
{
    if (this->accept(visitor) && depth != 0) {
        for (auto child : children)
            child->walk(visitor, depth - 1);
    }
    this->seeOff(visitor);
}

@node_name.1|bool Visitor::visit(%s *node) {return visit(static_cast<Node*>(node))\;}||\n|;
@node_name.1|void Visitor::leave(%s *node) {leave(static_cast<Node*>(node))\;}||\n|;

void AST::walk(Visitor *visitor, int depth)
{
    for (auto &root : roots())
        root->walk(visitor, depth);
}
@@

const size_t Parser::stackIncrementStep = 1024;

Parser::Parser():
@numb_tact?;...
    tokenActions(nullptr),
@@
@numb_pact?;...
    parseActions(nullptr),
@@
@numb_nact?;...
    nodeActions(nullptr),
@@
    stackTop(0),
    stateNum(0)
{
    stack.resize(stackIncrementStep);
}

Parser::~Parser()
{
}

void Parser::parse(const char *input)
{
    parse(input, std::strlen(input));
}

void Parser::parse(const char *input, size_t size)
{
    lexer.start(input);
    stateNum = 0;
    stackTop = 0;
    while (true) {
        lexer.next();
        const int termSymb = lexer.currentToken().termNum;
@numb_tact?;...
        if (tokenActions && tokenActionNumber[termSymb] >= 0) {
            switch(tokenActionNumber[termSymb]) {
                @tact_func.1|case %d: tokenActions->%s(termSymb, lexer.currentToken())\; break\;||\n                |;
            }
        }
@@
        while (true) {
            if (Bm[Br[stateNum] + Bc[termSymb]] & Bmask[termSymb]) { // Check B-matrix for shift action.
                if (++stackTop >= stack.size())
                    stack.resize(stack.size() + stackIncrementStep);
                stack[stackTop].state = stateNum;
                stack[stackTop].symbol = termSymb;
                stack[stackTop].tokens = TokenSequence(lexer.currentToken());
@numb_node?;...
                stack[stackTop].nodes.clear();
@@
                stateNum = Tm[Tr[stateNum] + Tc[termSymb]]; // Get next state from terminal transition matrix.
                while (stateNum <= 0) // While shift-reduce actions.
                    reduce(-stateNum);
                break;
            }
            int prodRule = Rr[stateNum] > 0 ? Rr[stateNum] : Rm[Rc[termSymb] - Rr[stateNum]];
            if (prodRule > 0) {
                reduce(prodRule);
                while (stateNum <= 0) // While shift-reduce actions.
                    reduce(-stateNum);
                continue;
            }
            if (stateNum == acceptState) {
                reduce(0); // last reduction when accept state reached.
@numb_node?;...
                roots().insert(roots().begin(), stack[stackTop].nodes.begin(), stack[stackTop].nodes.end());
@@
                return;
            }
            throw SyntaxError(src, input, size, stack.data() + 1, stackTop > 0 ? stackTop - 1 : 0, stateNum, lexer.currentToken());
        }
    }
}

void Parser::reduce(int prodRule)
{
    // Perform reduce related actions
    const size_t oldTop = stackTop;
    assert(static_cast<int>(stackTop) >= prodLen[prodRule]);
    stackTop -= prodLen[prodRule]; // Reduce stack ptr by production length.
@numb_pact?;...
    if (parseActions && parseActionNumber[prodRule] >= 0) {
        switch (parseActionNumber[prodRule]) {
            @pact_func.1|case %d: parseActions->%s(&stack[stackTop], prodLen[prodRule]+1)\; break\;||\n            |;
        }
    }
@@
    if (prodLen[prodRule] < 0) { // Null production?
        if (stackTop >= stack.size())
            stack.resize(stack.size() + stackIncrementStep);
        stack[stackTop].state = stateNum;
        stack[stackTop].tokens = TokenSequence();
@numb_node?;...
        stack[stackTop].nodes.clear();
@@
    }
@numb_node?;...
    switch (nodeNumber[prodRule]) {
        @node_name.1|case %d: addNode(new %s(&stack[stackTop], prodLen[prodRule]+1))\; break\;||\n        |;
        default:
            for (int i = 1; i < prodLen[prodRule]+1; ++i)
                stack[stackTop].nodes.insert(stack[stackTop].nodes.end(), stack[stackTop + i].nodes.begin(), stack[stackTop + i].nodes.end());
            break;
    }
@numb_nact?;...
    if (nodeActions) {
        switch (nodeActionNumber[prodRule]) {
            @nact_func.1|case %d: nodeActions->on%s(dynamic_cast<%s*>(stack[stackTop].nodes.front()))\; break\;||\n            |;
        }
    }
@@
@@
    if (stackTop < oldTop) {
        for (size_t pos = stackTop + 1; pos <= oldTop; ++pos)
            stack[stackTop].tokens.join(stack[pos].tokens);
@optn_debug?;...
        printf("===> Reduction %d matched the following text:\n%s\n", prodRule, std::string(stack[stackTop].tokens).c_str());
@@
    }
    // Reduce stack
    stack[stackTop].symbol = -nonterminalNumber[prodRule];
    stateNum = Nm[Nr[stack[stackTop].state] + Nc[prodRule]]; // Get next state from nonterminal transition.
}

@numb_node?;...
void Parser::addNode(Node *node)
{
    node->setSourcePath(src);
    nodes.push_back(std::unique_ptr<Node>(node));
    stack[stackTop].nodes.assign(1, node);
}

@@
const int Parser::acceptState = @accp_sta.d;;

const @prod_leng.t; Parser::prodLen[] =
{
    @prod_leng.20|%d|, |,\n    |;
};

// B_matrix.
const @bmat_numb.t; Parser::Bm[@bmat_numb.d;] =
{
    @bmat_numb.20|%d|, |,\n    |;
};

// B_matrix row.
const @bmat_row.t; Parser::Br[@bmat_row.d;] =
{
    @bmat_row.20|%d|, |,\n    |;
};

// B_matrix column.
const @bmat_col.t; Parser::Bc[@bmat_col.d;] =
{
    @bmat_col.20|%d|, |,\n    |;
};

@optn_bm.eq.2;...
// B_matrix column.
const @bmat_mask.t; Parser::Bmask[@bmat_mask.d;] =
{
    @bmat_mask.20|%d|, |,\n    |;
};
@@

// T_matrix.
const @tmat_numb.t; Parser::Tm [@tmat_numb.d;] =
{
    @tmat_numb.20|%d|, |,\n    |;
};

// T_matrix row.
const @tmat_row.t; Parser::Tr [@tmat_row.d;] =
{
    @tmat_row.20|%d|, |,\n    |;
};

// T_matrix column.
const @tmat_col.t; Parser::Tc [@tmat_col.d;] =
{
    @tmat_col.20|%d|, |,\n    |;
};

// N_matrix.
const @nmat_numb.t; Parser::Nm [@nmat_numb.d;] =
{
    @nmat_numb.20|%d|, |,\n    |;
};

// N_matrix row.
const @nmat_row.t; Parser::Nr [@nmat_row.d;] =
{
    @nmat_row.20|%d|, |,\n    |;
};

// N_matrix column.
const @nmat_col.t; Parser::Nc [@nmat_col.d;] =
{
    @nmat_col.20|%d|, |,\n    |;
};

// R_matrix.
const @rmat_numb.t; Parser::Rm [@rmat_numb.d;] =
{
    @rmat_numb.20|%d|, |,\n    |;
};

// R_matrix row.
const @rmat_row.t; Parser::Rr [@rmat_row.d;] =
{
    @rmat_row.20|%d|, |,\n    |;
};

// R_matrix column.
const @rmat_col.t; Parser::Rc [@rmat_col.d;] =
{
    @rmat_col.20|%d|, |,\n    |;
};
@numb_tact?;...

// Token action number
const @tact_numb.t; Parser::tokenActionNumber[@tact_numb.d;] =
{
    @tact_numb.20|%d|, |,\n    |;
};
@@
@numb_pact?;...

// Parser action number
const @pact_numb.t; Parser::parseActionNumber[@pact_numb.d;] =
{
    @pact_numb.20|%d|, |,\n    |;
};
@@
@numb_nact?;...

// Node action number
const @nact_numb.t; Parser::nodeActionNumber[@nact_numb.d;] =
{
    @nact_numb.20|%d|, |,\n    |;
};
@@

// Nonterminal number
const @prod_head.t; Parser::nonterminalNumber[@prod_head.d;] =
{
    @prod_head.20|%d|, |,\n    |;
};
@numb_node?;...

const @node_numb.t; Parser::nodeNumber[@node_numb.d;] =
{
    @node_numb.20|%d|, |,\n    |;
};
@@

} // namespace @grm_name;
